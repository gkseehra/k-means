{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62fa7a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "import string\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from scipy.spatial import distance\n",
    "import time\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem import PorterStemmer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77fcfbe",
   "metadata": {},
   "source": [
    "# 1. Lloyd k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "087c5308",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ck:\n",
    "    def __init__(self, df_dataset, k, t=0.1):\n",
    "        self.df_dataset = df_dataset.copy()\n",
    "        self.df_dataset_with_cluster = df_dataset.copy()\n",
    "        self.df_dataset_with_cluster['cluster'] = np.nan\n",
    "        self.k = k\n",
    "        self.t = t\n",
    "        self.centroids = self.initialize_centroids()\n",
    "        \n",
    "    def initialize_centroids(self):\n",
    "        centroid_indices = np.random.choice(self.df_dataset.index.array, size=self.k)\n",
    "        c_df = pd.DataFrame(self.df_dataset, index = centroid_indices)\n",
    "        c_df.reset_index(drop=True, inplace=True)\n",
    "        return c_df\n",
    "    \n",
    "    def calc_euclidean_dist(self, series_1, series_2):\n",
    "        return np.linalg.norm(np.array(series_1) - np.array(series_2))\n",
    "    \n",
    "    def re_initialize_centroids(self):\n",
    "        for c_index, _ in self.centroids.iterrows():\n",
    "            cluster = self.df_dataset[self.df_dataset_with_cluster['cluster'] == c_index]\n",
    "            cluster_size = cluster.shape[0]\n",
    "            if cluster_size == 0:\n",
    "                self.centroids.loc[c_index] = pd.DataFrame(self.df_dataset, index = np.random.choice(self.df_dataset.index.array, size=1)).squeeze()\n",
    "                continue\n",
    "            # Calculate average for this cluster.\n",
    "            row_sums = cluster.sum()\n",
    "            for col_name, summed_val in row_sums.iteritems(): \n",
    "                self.centroids.loc[c_index, col_name] = summed_val / cluster_size\n",
    "        self.centroids.reset_index(drop=True, inplace=True)\n",
    "                \n",
    "    def k_means(self):\n",
    "        prev_centroid_df = self.centroids\n",
    "        while True:\n",
    "            # Remove old cluster assignments.\n",
    "            self.df_dataset_with_cluster['cluster'] = np.nan\n",
    "            \n",
    "            \n",
    "            # Assign clusters.\n",
    "            euc_dist_mat = distance.cdist(self.df_dataset, self.centroids)\n",
    "            cluster_assignment = np.argmin(euc_dist_mat, axis=1)\n",
    "            self.df_dataset_with_cluster['cluster'] = cluster_assignment.tolist()\n",
    "            \n",
    "            # Re-initialize clusters.\n",
    "            self.re_initialize_centroids()\n",
    "            \n",
    "            # Calculate cluster difference between previous and current cluster\n",
    "            total_centroid_change = 0\n",
    "            for c_index, c in self.centroids.iterrows():\n",
    "                total_centroid_change += self.calc_euclidean_dist(prev_centroid_df.loc[c_index], c)\n",
    "            avg_centroid_change = total_centroid_change / self.k\n",
    "            \n",
    "            if avg_centroid_change < self.t:\n",
    "                break\n",
    "            prev_centroid_df = self.centroids\n",
    "        self.centroids = prev_centroid_df\n",
    "        return self.df_dataset_with_cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff0a5b2",
   "metadata": {},
   "source": [
    "# 2. k-means with SSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "854fd54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CkSSE:\n",
    "    def __init__(self, df_dataset, k, t=0.1):\n",
    "        self.df_dataset = df_dataset.copy()\n",
    "        self.df_dataset_with_cluster = df_dataset.copy()\n",
    "        self.df_dataset_with_cluster['cluster'] = np.nan\n",
    "        self.k = k\n",
    "        self.t = t\n",
    "        self.centroids = self.initialize_centroids()\n",
    "        \n",
    "    def initialize_centroids(self):\n",
    "        centroid_indices = np.random.choice(self.df_dataset.index.array, size=self.k)\n",
    "        c_df = pd.DataFrame(self.df_dataset, index = centroid_indices)\n",
    "        c_df.reset_index(drop=True, inplace=True)\n",
    "        return c_df\n",
    "    \n",
    "    def calc_euclidean_dist(self, series_1, series_2):\n",
    "        return np.linalg.norm(np.array(series_1) - np.array(series_2))\n",
    "    \n",
    "    def re_initialize_centroids(self):\n",
    "        for c_index, _ in self.centroids.iterrows():\n",
    "            cluster = self.df_dataset[self.df_dataset_with_cluster['cluster'] == c_index]\n",
    "            cluster_size = cluster.shape[0]\n",
    "            if cluster_size == 0:\n",
    "                self.centroids.loc[c_index] = pd.DataFrame(self.df_dataset, index = np.random.choice(self.df_dataset.index.array, size=1)).squeeze()\n",
    "                continue\n",
    "            # Calculate average for this cluster.\n",
    "            row_sums = cluster.sum()\n",
    "            for col_name, summed_val in row_sums.iteritems(): \n",
    "                self.centroids.loc[c_index, col_name] = summed_val / cluster_size\n",
    "        self.centroids.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    def calc_total_sse(self):\n",
    "        total_sse = 0\n",
    "        for c_index, _ in self.centroids.iterrows():\n",
    "            # for each cluster, calculate the euclidean distance of all data points in that cluster and the centroid.\n",
    "            curr_centroid = self.centroids.loc[c_index]\n",
    "            data_in_curr_cluster = self.df_dataset[self.df_dataset_with_cluster['cluster']==c_index]\n",
    "            sse_mat = distance.cdist(data_in_curr_cluster, self.centroids.loc[[c_index]])\n",
    "            total_sse += np.sum(np.square(sse_mat))\n",
    "        return total_sse\n",
    "                \n",
    "    def k_means(self):\n",
    "        prev_centroid_df = self.centroids\n",
    "        prev_total_sse = 0\n",
    "        while True:\n",
    "            # Remove old cluster assignments.\n",
    "            self.df_dataset_with_cluster['cluster'] = np.nan\n",
    "            \n",
    "            # Assign clusters.\n",
    "            euc_dist_mat = distance.cdist(self.df_dataset, self.centroids)\n",
    "            cluster_assignment = np.argmin(euc_dist_mat, axis=1)\n",
    "            self.df_dataset_with_cluster['cluster'] = cluster_assignment.tolist()\n",
    "                \n",
    "            # Re-initialize clusters.\n",
    "            self.re_initialize_centroids()\n",
    "            \n",
    "            # Calculate cluster difference between previous and current cluster\n",
    "            \n",
    "            curr_total_sse = self.calc_total_sse()\n",
    "            total_sse_change = abs(curr_total_sse-prev_total_sse)\n",
    "            \n",
    "            if total_sse_change < self.t:\n",
    "                break\n",
    "            prev_centroid_df = self.centroids\n",
    "            prev_total_sse = curr_total_sse\n",
    "        self.centroids = prev_centroid_df\n",
    "        return self.df_dataset_with_cluster, prev_total_sse\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d156477",
   "metadata": {},
   "source": [
    "# 3. k-means++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f7e1a265",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ckplusplus:\n",
    "    def __init__(self, df_dataset, k, t=0.1):\n",
    "        self.df_dataset = df_dataset.copy()\n",
    "        self.df_dataset_with_cluster = df_dataset.copy()\n",
    "        self.df_dataset_with_cluster['cluster'] = np.nan\n",
    "        self.k = k\n",
    "        self.t = t\n",
    "        self.centroids = self.initialize_centroids()\n",
    "        \n",
    "    def initialize_centroids(self):\n",
    "        centroid_indices = [np.random.choice(self.df_dataset.index.array)]\n",
    "        c_df = pd.DataFrame(self.df_dataset, index = centroid_indices)\n",
    "        c_df.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        for i in range(self.k - 1):\n",
    "            euc_dist_mat = np.min(np.square(distance.cdist(self.df_dataset, c_df)), axis=1)\n",
    "            prob_dist = (euc_dist_mat / np.sum(euc_dist_mat)).tolist()\n",
    "            new_centeroid_index = np.random.choice(self.df_dataset.index.array, p=prob_dist)\n",
    "            centroid_indices.append(new_centeroid_index)\n",
    "            c_df = pd.DataFrame(self.df_dataset, index = centroid_indices)\n",
    "            c_df.reset_index(drop=True, inplace=True)\n",
    "        return c_df\n",
    "    \n",
    "    def calc_euclidean_dist(self, series_1, series_2):\n",
    "        return np.linalg.norm(np.array(series_1) - np.array(series_2))\n",
    "    \n",
    "    def re_initialize_centroids(self):\n",
    "        for c_index, _ in self.centroids.iterrows():\n",
    "            cluster = self.df_dataset[self.df_dataset_with_cluster['cluster'] == c_index]\n",
    "            cluster_size = cluster.shape[0]\n",
    "            if cluster_size == 0:\n",
    "                c_df = self.centroids.copy()\n",
    "                c_df = c_df.drop(c_index)\n",
    "                euc_dist_mat = np.min(np.square(distance.cdist(self.df_dataset, c_df)), axis=1)\n",
    "                prob_dist = (euc_dist_mat / np.sum(euc_dist_mat)).tolist()\n",
    "                new_centeroid_index = np.random.choice(self.df_dataset.index.array, p=prob_dist)\n",
    "                self.centroids.loc[c_index] = pd.DataFrame(self.df_dataset, index = new_centeroid_index).squeeze()\n",
    "                continue\n",
    "            # Calculate average for this cluster.\n",
    "            row_sums = cluster.sum()\n",
    "            for col_name, summed_val in row_sums.iteritems(): \n",
    "                self.centroids.loc[c_index, col_name] = summed_val / cluster_size\n",
    "        self.centroids.reset_index(drop=True, inplace=True)\n",
    "                \n",
    "    def k_means(self):\n",
    "        prev_centroid_df = self.centroids\n",
    "        prev_total_sse = 0\n",
    "        while True:\n",
    "            # Remove old cluster assignments.\n",
    "            self.df_dataset_with_cluster['cluster'] = np.nan\n",
    "            \n",
    "            # Assign clusters.\n",
    "            euc_dist_mat = distance.cdist(self.df_dataset, self.centroids)\n",
    "            cluster_assignment = np.argmin(euc_dist_mat, axis=1)\n",
    "            self.df_dataset_with_cluster['cluster'] = cluster_assignment.tolist()\n",
    "                \n",
    "            # Re-initialize clusters.\n",
    "            self.re_initialize_centroids()\n",
    "            \n",
    "            # Calculate cluster difference between previous and current cluster\n",
    "            total_centroid_change = 0\n",
    "            for c_index, c in self.centroids.iterrows():\n",
    "                total_centroid_change += self.calc_euclidean_dist(prev_centroid_df.loc[c_index], c)\n",
    "            avg_centroid_change = total_centroid_change / self.k\n",
    "            \n",
    "            if avg_centroid_change < self.t:\n",
    "                break\n",
    "            prev_centroid_df = self.centroids\n",
    "        self.centroids = prev_centroid_df\n",
    "        return self.df_dataset_with_cluster\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
